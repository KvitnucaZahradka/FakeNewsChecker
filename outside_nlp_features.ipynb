{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pythonwhois  # i'm using this http://cryto.net/pythonwhois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.error import HTTPError\n",
    "from requests.exceptions import HTTPError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function that forces system to wait random time, with upper bound on wait equals to maxTime\n",
    "def waitRandomTime(maxTime=7):\n",
    "    ## setting up the seed\n",
    "    tm = int(round(time.time()))\n",
    "    random.seed(tm)\n",
    "\n",
    "    tim = random.randint(0, 8 * 100) / 100.0\n",
    "    time.sleep(tim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### safely open the saved pickle file\n",
    "def safelyOpen(nameOfSavedDictionary):\n",
    "    try:\n",
    "        with open(nameOfSavedDictionary + '.pickle', 'rb') as handle:\n",
    "            return pickle.load(handle)\n",
    "    except (NameError, FileNotFoundError):\n",
    "        print(\"File was not found \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def uniqify(seq):\n",
    "    # Not order preserving\n",
    "    keys = {}\n",
    "    for e in seq:\n",
    "        keys[e] = 1\n",
    "    return list(keys.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataFake = safelyOpen('fakeKaggleEnglishOver300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sites = dataFake.ix[:,'site_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls_fake = dataFake.ix[:,'site_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls_fake = urls_fake.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## creating sample urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_urls = ['nytimes.com', 'wsj.com', 'abcnews.go.com', 'cnn.com', 'cbsnews.com', 'foxnews.com', 'msnbc.com',\n",
    "                  'nbcnews.com','oann.com', 'latimes.com', 'usatoday.com', 'washingtonpost.com', 'newsweek.com',\n",
    "                  'time.com', 'usnews.com', 'theguardian.com', 'telegraph.co.uk', 'thetimes.co.uk', 'ft.com',\n",
    "                  'independent.co.uk', 'bbc.com', 'standard.co.uk', 'dailymail.co.uk', 'express.co.uk',\n",
    "                  'dailytelegraph.com.au', 'thestar.com','theglobeandmail.com', 'nationalpost.com',\n",
    "                   'calgaryherald.com', 'herald.ie', 'irishtimes.com', 'independent.ie', 'afr.com.au',\n",
    "                   'theaustralian.com.au', 'thesaturdaypaper.com.au', 'reddit.com', 'Cnn.com', 'Bbc.co.uk', 'Weather.com',\n",
    "                   'News.yahoo.com', 'Huffingtonpost.com','Forbes.com', 'Foxnews.com', 'news.google.com' ,\n",
    "                   'Shutterstock.com', 'Timesofindia.indiatimes.com', 'Bloomberg.com', 'Reuters.com', 'Wunderground.com',\n",
    "                   'Money.cnn.com', 'Indianexpress.com', 'Nbcnews.com', 'Latimes.com', 'cnbc.com', 'cbsnews.com',\n",
    "                   'vox.com', 'Abcnews.go.com', 'Nypost.com', 'Theatlantic.com', 'Chicagotribune.com', 'Chinadaily.com.cn'\n",
    "                   ,'Hollywoodreporter.com', 'Sfgate.com', 'Usnews.com', 'Economist.com', 'Aljazeera.com', 'Fortune.com',\n",
    "                   'Newsnow.co.uk', 'Variety.com', 'Euronews.com', 'Washingtontimes.com', 'Bostonglobe.com', 'Newsweek.com'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataTrue = safelyOpen('nytRawText2016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url_true = create_true_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_true = {key: [222, 999] for key in dataTrue.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_fake = {key: []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_true_urls():\n",
    "    return {key: good_urls[random_choice()] for key in dataTrue.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_choice():\n",
    "    return random.randint(0, len(good_urls) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### test my url analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pythonwhois  # it's using this http://cryto.net/pythonwhois\n",
    "from urllib.error import HTTPError\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "import random\n",
    "import urllib\n",
    "import helpful_functions\n",
    "import urllib.request\n",
    "import socket\n",
    "\n",
    "\n",
    "class url_analysis():\n",
    "\n",
    "    __final_dictionary = None\n",
    "    __data = None\n",
    "    __urls = None\n",
    "    __meta = None\n",
    "    __meta_data_name = None\n",
    "\n",
    "    # data = numerical data you already have\n",
    "    # urls = urls for the numerical data\n",
    "    # false = are data to be considered false or not false\n",
    "    def __init__(self, data, urls, false):\n",
    "        self.__data = data\n",
    "        self.__urls = urls\n",
    "\n",
    "        if false:\n",
    "            self.__meta_data_name = 'fake_urls_metadata'\n",
    "        else:\n",
    "            self.__meta_data_name = 'true_urls_metadata'\n",
    "\n",
    "\n",
    "    # strategy: loop through the urls that belong to data, for given url look into my precomputed metadata\n",
    "    # if you find url ok calculate url_analysis, if not query pythonwhois and calculate it after that and add to\n",
    "    # meta_data I am keeping offline\n",
    "\n",
    "    # MAIN FUNCTIONS\n",
    "    def __open_and_produce_url_meta(self):\n",
    "        self.__meta = helpful_functions.safely_open(self.__meta_data_name, pick=True)\n",
    "\n",
    "        # NOTE: fix this function tomorrow\n",
    "        if self.__meta is not None:\n",
    "            uniq = helpful_functions.uniqify(self.__urls.values())\n",
    "            difference = set(uniq) - set(self.__meta)\n",
    "            if difference is not None:\n",
    "                print('difference is not empty, is of size: ' + str(len(difference)))\n",
    "                print('we add it to self.__meta, that is of size: ' + str(len(self.__meta)))\n",
    "\n",
    "                add_to_meta = {}\n",
    "                self.__find_url_meta(difference, add_to_meta)\n",
    "                helpful_functions.add_dict(self.__meta, add_to_meta)\n",
    "\n",
    "                print('we added missing urls metadata to self.__meta, now it is of size: ' + str(len(self.__meta)))\n",
    "                print('saving the meta on disc')\n",
    "                helpful_functions.save_to_file(self.__meta, self.__meta_data_name, pick=True)\n",
    "\n",
    "        else:\n",
    "            self.__meta = {}\n",
    "            self.__find_url_meta(self.__urls.values(), self.__meta)\n",
    "            helpful_functions.save_to_file(self.__meta, self.__meta_data_name, pick=True)\n",
    "\n",
    "    # looping through the article ids and adding the outside url features, as calculated from appropriate meta\n",
    "    def url_analysis(self):\n",
    "        self.__open_and_produce_url_meta()\n",
    "\n",
    "        # looking for creation date\n",
    "        for key in self.__data.keys():\n",
    "            url = self.__urls[key]\n",
    "            try:\n",
    "                year = int(self.__meta[url]['creation_date'][0].year)\n",
    "            except (TypeError, KeyError):\n",
    "                year = 2000\n",
    "\n",
    "            #year_bias = self.__year_bias(year)\n",
    "            year_bias = self.__sigmoid_year(year)\n",
    "            self.__data[key].extend(year_bias)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # this is proxy 0 function, you better should do some clustering will be proxy 1\n",
    "    # maybe you should implement this as sigmoid function from 1900 ---> 1 and 2017 --> -1, centered at 2000 ???\n",
    "    def __year_bias(self, year):\n",
    "        if year < 2000:\n",
    "            return [1]\n",
    "        elif year > 2000:\n",
    "            return [-1]\n",
    "        else:\n",
    "            return [0]\n",
    "        \n",
    "        \n",
    "    def __sigmoid_year(self, year):\n",
    "        return [self.__sigmoid(year)]\n",
    "\n",
    "    def __find_url_meta(self, domains, meta_fake):\n",
    "        if type(meta_fake) == dict:\n",
    "            for dom in domains:\n",
    "                try:\n",
    "                    print(dom)\n",
    "                    meta_fake[dom] = pythonwhois.get_whois(dom)\n",
    "                except (urllib.request.HTTPError, HTTPError, ConnectionResetError, UnicodeDecodeError):\n",
    "                    helpful_functions.wait_random_time(45)\n",
    "                except (KeyError, socket.gaierror):\n",
    "                    meta_fake[dom] = None\n",
    "                except pythonwhois.shared.WhoisException:\n",
    "                    meta_fake[dom] = None\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "    # HELPFUL FUNCTIONS\n",
    "\n",
    "    # getting data from outside\n",
    "    def get_data(self):\n",
    "        return self.__data\n",
    "    \n",
    "    def __sigmoid(self, x, alpha=0.3, shift=2000):\n",
    "        return (1 / (1 + math.exp(-alpha*(x - shift))))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del(true_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_analysis = url_analysis(num_true, url_true, false=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "difference is not empty, is of size: 1\n",
      "we add it to self.__meta, that is of size: 71\n",
      "Indianexpress.com\n",
      "we added missing urls metadata to self.__meta, now it is of size: 71\n",
      "saving the meta on disc\n"
     ]
    }
   ],
   "source": [
    "true_analysis.url_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(num_true[list(num_true.keys())[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x, alpha=0.3, shift=2000):\n",
    "    return (1 / (1 + math.exp(-alpha*(x - shift))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35434369377420455"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(1998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sites = uniqify(sites)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': ['91991_DOMAIN_COM-VRSN'], 'status': ['clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)', 'clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)', 'clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)', 'serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)', 'serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)', 'serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)'], 'creation_date': [datetime.datetime(1994, 1, 17, 21, 0)], 'expiration_date': [datetime.datetime(2023, 1, 18, 21, 0), datetime.datetime(2023, 1, 18, 21, 0)], 'updated_date': [datetime.datetime(2016, 10, 21, 15, 12, 35)], 'registrar': ['MarkMonitor, Inc.'], 'whois_server': ['whois.markmonitor.com'], 'nameservers': ['dns-plx.ewr1.nytimes.com', 'ns2.p24.dynect.net', 'dns-plx.sea1.nytimes.com', 'ns4.p24.dynect.net', 'ns3.p24.dynect.net', 'ns1.p24.dynect.net'], 'emails': ['abusecomplaints@markmonitor.com'], 'contacts': {'registrant': {'name': 'Domain Administrator', 'organization': 'The New York Times Company', 'city': 'New York', 'state': 'NY', 'postalcode': '10018', 'country': 'US', 'phone': '+1.2125561234', 'fax': '+1.2125561234', 'email': 'hostmaster@nytimes.com', 'street': '620 8th Avenue,'}, 'tech': {'name': 'Domain Administrator', 'organization': 'The New York Times Company', 'city': 'New York', 'state': 'NY', 'postalcode': '10018', 'country': 'US', 'phone': '+1.2125561234', 'fax': '+1.1231231234', 'email': 'hostmaster@nytimes.com', 'street': '620 8th Avenue,'}, 'admin': {'name': 'Ellen Herb', 'organization': 'The New York Times Company', 'city': 'NEW YORK', 'state': 'NY', 'postalcode': '10018', 'country': 'US', 'phone': '+1.2125561234', 'fax': '+1.2125561234', 'email': 'hostmaster@nytimes.com', 'street': '620 8th Avenue,'}, 'billing': None}, 'raw': [\"Domain Name: nytimes.com\\nRegistry Domain ID: 91991_DOMAIN_COM-VRSN\\nRegistrar WHOIS Server: whois.markmonitor.com\\nRegistrar URL: http://www.markmonitor.com\\nUpdated Date: 2016-10-21T15:12:35-0700\\nCreation Date: 1994-01-17T21:00:00-0800\\nRegistrar Registration Expiration Date: 2023-01-18T21:00:00-0800\\nRegistrar: MarkMonitor, Inc.\\nRegistrar IANA ID: 292\\nRegistrar Abuse Contact Email: abusecomplaints@markmonitor.com\\nRegistrar Abuse Contact Phone: +1.2083895740\\nDomain Status: clientUpdateProhibited (https://www.icann.org/epp#clientUpdateProhibited)\\nDomain Status: clientTransferProhibited (https://www.icann.org/epp#clientTransferProhibited)\\nDomain Status: clientDeleteProhibited (https://www.icann.org/epp#clientDeleteProhibited)\\nDomain Status: serverUpdateProhibited (https://www.icann.org/epp#serverUpdateProhibited)\\nDomain Status: serverTransferProhibited (https://www.icann.org/epp#serverTransferProhibited)\\nDomain Status: serverDeleteProhibited (https://www.icann.org/epp#serverDeleteProhibited)\\nRegistry Registrant ID: \\nRegistrant Name: Domain Administrator\\nRegistrant Organization: The New York Times Company\\nRegistrant Street: 620 8th Avenue, \\nRegistrant City: New York\\nRegistrant State/Province: NY\\nRegistrant Postal Code: 10018\\nRegistrant Country: US\\nRegistrant Phone: +1.2125561234\\nRegistrant Phone Ext: \\nRegistrant Fax: +1.2125561234\\nRegistrant Fax Ext: \\nRegistrant Email: hostmaster@nytimes.com\\nRegistry Admin ID: \\nAdmin Name: Ellen Herb\\nAdmin Organization: The New York Times Company\\nAdmin Street: 620 8th Avenue, \\nAdmin City: NEW YORK\\nAdmin State/Province: NY\\nAdmin Postal Code: 10018\\nAdmin Country: US\\nAdmin Phone: +1.2125561234\\nAdmin Phone Ext: \\nAdmin Fax: +1.2125561234\\nAdmin Fax Ext: \\nAdmin Email: hostmaster@nytimes.com\\nRegistry Tech ID: \\nTech Name: Domain Administrator\\nTech Organization: The New York Times Company\\nTech Street: 620 8th Avenue, \\nTech City: New York\\nTech State/Province: NY\\nTech Postal Code: 10018\\nTech Country: US\\nTech Phone: +1.2125561234\\nTech Phone Ext: \\nTech Fax: +1.1231231234\\nTech Fax Ext: \\nTech Email: hostmaster@nytimes.com\\nName Server: dns-plx.ewr1.nytimes.com\\nName Server: ns2.p24.dynect.net\\nName Server: dns-plx.sea1.nytimes.com\\nName Server: ns4.p24.dynect.net\\nName Server: ns3.p24.dynect.net\\nName Server: ns1.p24.dynect.net\\nDNSSEC: unsigned\\nURL of the ICANN WHOIS Data Problem Reporting System: http://wdprs.internic.net/\\n>>> Last update of WHOIS database: 2017-01-30T20:18:34-0800 <<<\\n\\nThe Data in MarkMonitor.com's WHOIS database is provided by MarkMonitor.com for\\ninformation purposes, and to assist persons in obtaining information about or\\nrelated to a domain name registration record.  MarkMonitor.com does not guarantee\\nits accuracy.  By submitting a WHOIS query, you agree that you will use this Data\\nonly for lawful purposes and that, under no circumstances will you use this Data to:\\n (1) allow, enable, or otherwise support the transmission of mass unsolicited,\\n     commercial advertising or solicitations via e-mail (spam); or\\n (2) enable high volume, automated, electronic processes that apply to\\n     MarkMonitor.com (or its systems).\\nMarkMonitor.com reserves the right to modify these terms at any time.\\nBy submitting this query, you agree to abide by this policy.\\n\\nMarkMonitor is the Global Leader in Online Brand Protection.\\n\\nMarkMonitor Domain Management(TM)\\nMarkMonitor Brand Protection(TM)\\nMarkMonitor AntiPiracy(TM)\\nMarkMonitor AntiFraud(TM)\\nProfessional and Managed Services\\n\\nVisit MarkMonitor at http://www.markmonitor.com\\nContact us at +1.8007459229\\nIn Europe, at +44.02032062220\\n\\nFor more information on Whois status codes, please visit\\n https://www.icann.org/resources/pages/epp-status-codes-2014-06-16-en\\n--\\n\", '\\n   Domain Name: NYTIMES.COM\\n   Registrar: MARKMONITOR INC.\\n   Sponsoring Registrar IANA ID: 292\\n   Whois Server: whois.markmonitor.com\\n   Referral URL: http://www.markmonitor.com\\n   Name Server: DNS-PLX.EWR1.NYTIMES.COM\\n   Name Server: DNS-PLX.SEA1.NYTIMES.COM\\n   Name Server: NS1.P24.DYNECT.NET\\n   Name Server: NS2.P24.DYNECT.NET\\n   Name Server: NS3.P24.DYNECT.NET\\n   Name Server: NS4.P24.DYNECT.NET\\n   Status: clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\\n   Status: clientTransferProhibited https://icann.org/epp#clientTransferProhibited\\n   Status: clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\\n   Status: serverDeleteProhibited https://icann.org/epp#serverDeleteProhibited\\n   Status: serverTransferProhibited https://icann.org/epp#serverTransferProhibited\\n   Status: serverUpdateProhibited https://icann.org/epp#serverUpdateProhibited\\n   Updated Date: 21-oct-2016\\n   Creation Date: 18-jan-1994\\n   Expiration Date: 19-jan-2023']}\n"
     ]
    }
   ],
   "source": [
    "domains = ['nytimes.com']\n",
    "for dom in domains:\n",
    "    details = pythonwhois.get_whois(dom)\n",
    "    print(details)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'status', 'creation_date', 'expiration_date', 'updated_date', 'registrar', 'whois_server', 'nameservers', 'emails', 'contacts', 'raw'])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(1994, 1, 17, 21, 0)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "details['creation_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_url_meta(domains, meta_fake):\n",
    "    if type(meta_fake) == dict:\n",
    "        for dom in domains:\n",
    "            try:\n",
    "                print(dom)\n",
    "                meta_fake[dom] = pythonwhois.get_whois(dom)\n",
    "            except (urllib.request.HTTPError, HTTPError, ConnectionResetError, UnicodeDecodeError):\n",
    "                waitRandomTime(45)\n",
    "            except KeyError:\n",
    "                meta_fake[dom] = None\n",
    "            except pythonwhois.shared.WhoisException:\n",
    "                meta_fake[dom] = None\n",
    "    else:\n",
    "        raise ValueError\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_fake_old = meta_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_fake = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100percentfedup.com\n",
      "21stcenturywire.com\n",
      "abcnews.com.co\n",
      "abeldanger.net\n",
      "abovetopsecret.com\n",
      "activistpost.com\n",
      "addictinginfo.org\n",
      "adobochronicles.com\n",
      "ahtribune.com\n",
      "allnewspipeline.com\n",
      "americanlookout.com\n",
      "americasfreedomfighters.com\n",
      "amren.com\n",
      "amtvmedia.com\n",
      "anonews.co\n",
      "anonhq.com\n",
      "antiwar.com\n",
      "awdnews.com\n",
      "barenakedislam.com\n",
      "beforeitsnews.com\n",
      "betootaadvocate.com\n",
      "bigbluevision.org\n",
      "bignuggetnews.com\n",
      "bipartisanreport.com\n",
      "blackagendareport.com\n",
      "blacklistednews.com\n",
      "breitbart.com\n",
      "christiantimesnewspaper.com\n",
      "chronicle.su\n",
      "clickhole.com\n",
      "coasttocoastam.com\n",
      "collective-evolution.com\n",
      "consciouslifenews.com\n",
      "conservativedailypost.com\n",
      "conservativetribune.com\n",
      "consortiumnews.com\n",
      "corbettreport.com\n",
      "countercurrents.org\n",
      "counterpunch.org\n",
      "dailynewsbin.com\n",
      "dailysquib.co.uk\n",
      "dailystormer.com\n",
      "dailywire.com\n",
      "darkmoon.me\n",
      "davidduke.com\n",
      "davidstockmanscontracorner.com\n",
      "davidwolfe.com\n",
      "dcclothesline.com\n",
      "defenddemocracy.press\n",
      "dennismichaellynch.com\n",
      "departed.co\n",
      "disclose.tv\n",
      "donaldtrumpnews.co\n",
      "educateinspirechange.org\n",
      "empireherald.com\n",
      "endingthefed.com\n",
      "endoftheamericandream.com\n",
      "endtime.com\n",
      "eutimes.net\n",
      "ewao.com\n",
      "fellowshipoftheminds.com\n",
      "filmsforaction.org\n",
      "foreignpolicyjournal.com\n",
      "fort-russ.com\n",
      "freedomoutpost.com\n",
      "fromthetrenchesworldreport.com\n",
      "frontpagemag.com\n",
      "galacticconnection.com\n",
      "geoengineeringwatch.org\n",
      "globalresearch.ca\n",
      "godlikeproductions.com\n",
      "gomerblog.com\n",
      "govtslaves.info\n",
      "greanvillepost.com\n",
      "guardianlv.com\n",
      "gulagbound.com\n",
      "hangthebankers.com\n",
      "healthimpactnews.com\n",
      "henrymakow.com\n",
      "humansarefree.com\n",
      "ifyouonlynews.com\n",
      "ihavethetruth.com\n",
      "ijr.com\n",
      "in5d.com\n",
      "indiaarising.com\n",
      "informationclearinghouse.info\n",
      "infowars.com\n",
      "intellihub.com\n",
      "intrepidreport.com\n",
      "investmentresearchdynamics.com\n",
      "investmentwatchblog.com\n",
      "jewsnews.co.il\n",
      "journal-neo.org\n",
      "katehon.com\n",
      "kingworldnews.com\n",
      "lewrockwell.com\n",
      "liberalamerica.org\n",
      "libertyblitzkrieg.com\n",
      "libertynews.com\n",
      "libertyunyielding.com\n",
      "libertywritersnews.com\n",
      "madworldnews.com\n",
      "miniplanet.us\n",
      "mintpressnews.com\n",
      "moonofalabama.org\n",
      "morningnewsusa.com\n",
      "nakedcapitalism.com\n",
      "naturalblaze.com\n",
      "naturalnews.com\n",
      "ncscooper.com\n",
      "newcenturytimes.com\n",
      "newsbiscuit.com\n",
      "newstarget.com\n",
      "newsthump.com\n",
      "nowtheendbegins.com\n",
      "nutritionfacts.org\n",
      "occupydemocrats.com\n",
      "off-guardian.org\n",
      "opednews.com\n",
      "orientalreview.org\n",
      "other98.com\n",
      "pakalertpress.com\n",
      "patriotrising.com\n",
      "paulcraigroberts.org\n",
      "politicususa.com\n",
      "pravdareport.com\n",
      "prepperwebsite.com\n",
      "presidentialvoting2016.com\n",
      "presstv.com\n",
      "presstv.ir\n",
      "prisonplanet.com\n",
      "projectveritas.com\n",
      "proudemocrat.com\n",
      "rbth.com\n",
      "readynutrition.com\n",
      "realfarmacy.com\n",
      "redflagnews.com\n",
      "reductress.com\n",
      "regated.com\n",
      "rense.com\n",
      "returnofkings.com\n",
      "rinf.com\n",
      "ronpaulinstitute.org\n",
      "rt.com\n",
      "russia-direct.org\n",
      "russia-insider.com\n",
      "satirewire.com\n",
      "sgtreport.com\n",
      "shadowproof.com\n",
      "shiftfrequency.com\n",
      "shtfplan.com\n",
      "silverdoctors.com\n",
      "sott.net\n",
      "southfront.org\n",
      "spinzon.com\n",
      "sputniknews.com\n",
      "strategic-culture.org\n",
      "survivopedia.com\n",
      "the-newspapers.com\n",
      "theantimedia.org\n",
      "thecommonsenseshow.com\n",
      "thecontroversialfiles.net\n",
      "thedailybell.com\n",
      "thedailysheeple.com\n",
      "thedailywtf.com\n",
      "theduran.com\n",
      "theearthchild.co.za\n",
      "theeconomiccollapseblog.com\n",
      "theeventchronicle.com\n",
      "thefederalistpapers.org\n",
      "thefreethoughtproject.com\n",
      "thelastlineofdefense.org\n",
      "themindunleashed.com\n",
      "thenewamerican.com\n",
      "theonion.com\n",
      "thepeoplescube.com\n",
      "thepoke.co.uk\n",
      "therussophile.org\n",
      "thesaker.is\n",
      "thesleuthjournal.com\n",
      "thespoof.com\n",
      "thetruthseeker.co.uk\n",
      "theunrealtimes.com\n",
      "topinfopost.com\n",
      "toprightnews.com\n",
      "trueactivist.com\n",
      "trunews.com\n",
      "truth-out.org\n",
      "truthdig.com\n",
      "truthfeed.com\n",
      "twitchy.com\n",
      "ufoholic.com\n",
      "undergroundhealth.com\n",
      "unz.com\n",
      "usanewsflash.com\n",
      "usanewsinsider.com\n",
      "usapoliticsnow.com\n",
      "usasupreme.com\n",
      "usatwentyfour.com\n",
      "usuncut.com\n",
      "vdare.com\n",
      "veteransnewsnow.com\n",
      "veteranstoday.com\n",
      "vigilantcitizen.com\n",
      "viralliberty.com\n",
      "voltairenet.org\n",
      "wakingtimes.com\n",
      "washingtonsblog.com\n",
      "waterfordwhispersnews.com\n",
      "wearechange.org\n",
      "westernjournalism.com\n",
      "whatreallyhappened.com\n",
      "whydontyoutrythis.com\n",
      "wikileaks.org\n",
      "winningdemocrats.com\n",
      "wnd.com\n",
      "worldtruth.tv\n",
      "wundergroundmusic.com\n",
      "yournewswire.com\n",
      "zerohedge.com\n"
     ]
    }
   ],
   "source": [
    "find_url_meta(sites, meta_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(meta_fake.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globalresearch.ca\n",
      "theearthchild.co.za\n"
     ]
    }
   ],
   "source": [
    "for key in meta_fake.keys():\n",
    "    if meta_fake[key] == None:\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lal = meta_fake['100percentfedup.com']['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contacts': {'admin': None,\n",
       "  'billing': None,\n",
       "  'registrant': None,\n",
       "  'tech': None},\n",
       " 'creation_date': [datetime.datetime(2012, 3, 13, 0, 0)],\n",
       " 'expiration_date': [datetime.datetime(2020, 9, 29, 0, 0)],\n",
       " 'nameservers': ['ED.NS.CLOUDFLARE.COM', 'GINA.NS.CLOUDFLARE.COM'],\n",
       " 'raw': ['Domain Name: 100PERCENTFEDUP.COM\\nRegistrar URL: http://www.godaddy.com\\nRegistrant Name: Registration Private\\nRegistrant Organization: Domains By Proxy, LLC\\nName Server: ED.NS.CLOUDFLARE.COM\\nName Server: GINA.NS.CLOUDFLARE.COM\\nDNSSEC: unsigned\\n\\nFor complete domain details go to:\\nhttp://who.godaddy.com/whoischeck.aspx?domain=100PERCENTFEDUP.COM\\n\\nThe data contained in GoDaddy.com, LLC\\'s WhoIs database,\\nwhile believed by the company to be reliable, is provided \"as is\"\\nwith no guarantee or warranties regarding its accuracy.  This\\ninformation is provided for the sole purpose of assisting you\\nin obtaining information about domain name registration records.\\nAny use of this data for any other purpose is expressly forbidden without the prior written\\npermission of GoDaddy.com, LLC.  By submitting an inquiry,\\nyou agree to these terms of usage and limitations of warranty.  In particular,\\nyou agree not to use this data to allow, enable, or otherwise make possible,\\ndissemination or collection of this data, in part or in its entirety, for any\\npurpose, such as the transmission of unsolicited advertising and\\nand solicitations of any kind, including spam.  You further agree\\nnot to use this data to enable high volume, automated or robotic electronic\\nprocesses designed to collect or compile this data for any purpose,\\nincluding mining this data for your own personal or commercial purposes. \\n\\nPlease note: the registrant of the domain name is specified\\nin the \"registrant\" section.  In most cases, GoDaddy.com, LLC \\nis not the registrant of domain names listed in this database.\\n',\n",
       "  '   Domain Name: 100PERCENTFEDUP.COM\\n   Registrar: GODADDY.COM, LLC\\n   Sponsoring Registrar IANA ID: 146\\n   Whois Server: whois.godaddy.com\\n   Referral URL: http://www.godaddy.com\\n   Name Server: ED.NS.CLOUDFLARE.COM\\n   Name Server: GINA.NS.CLOUDFLARE.COM\\n   Status: clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited\\n   Status: clientRenewProhibited https://icann.org/epp#clientRenewProhibited\\n   Status: clientTransferProhibited https://icann.org/epp#clientTransferProhibited\\n   Status: clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited\\n   Updated Date: 07-aug-2015\\n   Creation Date: 13-mar-2012\\n   Expiration Date: 29-sep-2020'],\n",
       " 'registrar': ['GODADDY.COM, LLC'],\n",
       " 'status': ['clientDeleteProhibited https://icann.org/epp#clientDeleteProhibited',\n",
       "  'clientRenewProhibited https://icann.org/epp#clientRenewProhibited',\n",
       "  'clientTransferProhibited https://icann.org/epp#clientTransferProhibited',\n",
       "  'clientUpdateProhibited https://icann.org/epp#clientUpdateProhibited'],\n",
       " 'updated_date': [datetime.datetime(2015, 8, 7, 0, 0)],\n",
       " 'whois_server': ['whois.godaddy.com']}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_fake['100percentfedup.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2012, 3, 13, 0, 0)]\n",
      "[datetime.datetime(2009, 11, 3, 0, 0)]\n",
      "[datetime.datetime(2015, 10, 26, 21, 56, 34), datetime.datetime(2015, 10, 26, 21, 56, 34)]\n",
      "[datetime.datetime(2010, 5, 12, 0, 0)]\n",
      "[datetime.datetime(1997, 5, 18, 0, 0)]\n",
      "[datetime.datetime(2010, 4, 23, 0, 0)]\n",
      "[datetime.datetime(2010, 9, 5, 20, 33, 25)]\n",
      "[datetime.datetime(2013, 6, 25, 0, 0)]\n",
      "[datetime.datetime(2015, 8, 23, 8, 8, 39)]\n",
      "[datetime.datetime(2014, 7, 7, 0, 0)]\n",
      "[datetime.datetime(2016, 5, 10, 0, 0)]\n",
      "[datetime.datetime(2013, 12, 17, 10, 41, 40)]\n",
      "[datetime.datetime(1995, 8, 11, 4, 0)]\n",
      "[datetime.datetime(2012, 1, 31, 0, 0)]\n",
      "[datetime.datetime(2015, 12, 16, 22, 42, 2), datetime.datetime(2015, 12, 16, 22, 42, 2)]\n",
      "[datetime.datetime(2014, 4, 11, 0, 0)]\n",
      "[datetime.datetime(1995, 12, 9, 0, 0)]\n",
      "[datetime.datetime(2012, 1, 16, 4, 0)]\n",
      "[datetime.datetime(2008, 7, 9, 6, 5, 5)]\n",
      "[datetime.datetime(2007, 9, 15, 0, 0)]\n",
      "[datetime.datetime(2014, 10, 2, 7, 17, 29)]\n",
      "[datetime.datetime(2016, 7, 25, 11, 4, 37)]\n",
      "[datetime.datetime(2016, 1, 15, 0, 0)]\n",
      "[datetime.datetime(2012, 2, 9, 2, 23, 25)]\n",
      "[datetime.datetime(2006, 6, 9, 0, 0)]\n",
      "[datetime.datetime(2006, 3, 1, 2, 1, 32)]\n",
      "[datetime.datetime(1999, 3, 14, 0, 0)]\n",
      "[datetime.datetime(2015, 12, 14, 0, 0)]\n",
      "[datetime.datetime(2010, 10, 9, 0, 0)]\n",
      "[datetime.datetime(2009, 6, 12, 4, 0)]\n",
      "[datetime.datetime(1999, 4, 20, 21, 0)]\n",
      "[datetime.datetime(2009, 6, 17, 2, 21, 16)]\n",
      "[datetime.datetime(2010, 5, 15, 1, 37)]\n",
      "[datetime.datetime(2016, 5, 31, 16, 21)]\n",
      "[datetime.datetime(2013, 10, 21, 18, 53)]\n",
      "[datetime.datetime(1998, 5, 18, 4, 0)]\n",
      "[datetime.datetime(2007, 4, 26, 0, 0)]\n",
      "[datetime.datetime(2001, 11, 9, 9, 9, 42)]\n",
      "[datetime.datetime(1998, 11, 23, 5, 0)]\n",
      "[datetime.datetime(2015, 2, 16, 0, 0)]\n",
      "[datetime.datetime(2007, 2, 19, 0, 0), datetime.datetime(2007, 2, 19, 0, 0), datetime.datetime(2007, 2, 19, 0, 0)]\n",
      "[datetime.datetime(2013, 3, 20, 0, 0)]\n",
      "[datetime.datetime(1998, 5, 14, 0, 0)]\n",
      "[datetime.datetime(2010, 1, 12, 0, 17, 16)]\n",
      "[datetime.datetime(1998, 12, 6, 5, 0)]\n",
      "[datetime.datetime(2014, 1, 13, 0, 0)]\n",
      "[datetime.datetime(1999, 7, 19, 4, 0)]\n",
      "[datetime.datetime(2013, 2, 18, 9, 30, 30)]\n",
      "[datetime.datetime(2015, 10, 13, 13, 5, 8)]\n",
      "[datetime.datetime(2011, 8, 25, 0, 0)]\n",
      "[datetime.datetime(2016, 2, 22, 20, 33, 55), datetime.datetime(2016, 2, 22, 20, 33, 55)]\n",
      "[datetime.datetime(2007, 1, 6, 18, 12, 14)]\n",
      "[datetime.datetime(2016, 4, 28, 21, 52, 31), datetime.datetime(2016, 4, 28, 21, 52, 31)]\n",
      "[datetime.datetime(2013, 6, 3, 3, 49, 56)]\n",
      "[datetime.datetime(2016, 1, 24, 0, 0)]\n",
      "[datetime.datetime(2016, 3, 14, 15, 0, 21)]\n",
      "[datetime.datetime(2010, 1, 29, 0, 0)]\n",
      "[datetime.datetime(1995, 8, 13, 4, 0)]\n",
      "[datetime.datetime(2009, 10, 26, 21, 8)]\n",
      "[datetime.datetime(2002, 5, 23, 0, 0)]\n",
      "[datetime.datetime(2013, 9, 12, 0, 0)]\n",
      "[datetime.datetime(2007, 3, 7, 9, 42, 16)]\n",
      "[datetime.datetime(2008, 9, 20, 22, 46, 38)]\n",
      "[datetime.datetime(2016, 2, 1, 0, 0)]\n",
      "[datetime.datetime(2008, 8, 29, 0, 0)]\n",
      "[datetime.datetime(2010, 11, 7, 18, 3, 31)]\n",
      "[datetime.datetime(1998, 4, 27, 4, 0)]\n",
      "[datetime.datetime(2012, 2, 8, 0, 0)]\n",
      "[datetime.datetime(2009, 11, 30, 7, 5, 15)]\n",
      "no creation date for globalresearch.ca\n",
      "[datetime.datetime(2000, 7, 26, 4, 0)]\n",
      "[datetime.datetime(2013, 6, 17, 18, 56, 5)]\n",
      "[datetime.datetime(2010, 2, 2, 20, 23, 8)]\n",
      "[datetime.datetime(2009, 10, 9, 13, 13, 54)]\n",
      "[datetime.datetime(2012, 2, 3, 0, 0)]\n",
      "[datetime.datetime(2010, 5, 21, 0, 9, 25)]\n",
      "[datetime.datetime(2012, 3, 6, 9, 4, 42)]\n",
      "[datetime.datetime(2011, 1, 11, 7, 37)]\n",
      "[datetime.datetime(2004, 8, 31, 15, 11, 22)]\n",
      "[datetime.datetime(2010, 12, 22, 0, 0)]\n",
      "[datetime.datetime(2014, 9, 19, 0, 0)]\n",
      "[datetime.datetime(2009, 7, 23, 0, 0)]\n",
      "[datetime.datetime(1996, 8, 15, 0, 0)]\n",
      "[datetime.datetime(2009, 4, 18, 21, 29, 54)]\n",
      "[datetime.datetime(2016, 4, 15, 0, 0)]\n",
      "[datetime.datetime(2003, 2, 5, 21, 18, 49)]\n",
      "[datetime.datetime(1999, 3, 7, 5, 0)]\n",
      "[datetime.datetime(2001, 11, 4, 0, 0)]\n",
      "[datetime.datetime(2011, 1, 25, 0, 47, 32)]\n",
      "[datetime.datetime(2013, 10, 25, 0, 0)]\n",
      "[datetime.datetime(2010, 2, 7, 4, 17, 30)]\n",
      "no creation date for jewsnews.co.il\n",
      "[datetime.datetime(2013, 2, 8, 7, 11, 57)]\n",
      "[datetime.datetime(2014, 12, 20, 10, 10, 34)]\n",
      "[datetime.datetime(2009, 3, 23, 0, 0)]\n",
      "[datetime.datetime(1999, 1, 28, 0, 0)]\n",
      "[datetime.datetime(2013, 3, 24, 7, 35, 8)]\n",
      "[datetime.datetime(2012, 3, 3, 21, 43, 1)]\n",
      "[datetime.datetime(2002, 10, 27, 0, 0)]\n",
      "[datetime.datetime(2012, 11, 11, 0, 0)]\n",
      "[datetime.datetime(2016, 6, 1, 3, 29)]\n",
      "[datetime.datetime(2013, 12, 25, 0, 0)]\n",
      "[datetime.datetime(2016, 1, 27, 5, 8, 28)]\n",
      "[datetime.datetime(2012, 2, 6, 0, 0)]\n",
      "[datetime.datetime(2004, 7, 1, 9, 20, 48)]\n",
      "[datetime.datetime(2013, 8, 22, 0, 0)]\n",
      "[datetime.datetime(2005, 1, 1, 4, 0, 45)]\n",
      "[datetime.datetime(2013, 3, 19, 0, 0)]\n",
      "[datetime.datetime(2005, 2, 19, 0, 0)]\n",
      "[datetime.datetime(2014, 6, 9, 12, 44, 19)]\n",
      "[datetime.datetime(2016, 2, 21, 0, 0)]\n",
      "[datetime.datetime(2006, 7, 11, 14, 29, 27)]\n",
      "[datetime.datetime(1996, 11, 2, 0, 0)]\n",
      "[datetime.datetime(2010, 10, 3, 10, 22)]\n",
      "[datetime.datetime(2008, 10, 18, 0, 0)]\n",
      "[datetime.datetime(2000, 3, 5, 1, 33, 16)]\n",
      "[datetime.datetime(2012, 12, 25, 19, 25, 18)]\n",
      "[datetime.datetime(2015, 4, 15, 12, 15, 8)]\n",
      "[datetime.datetime(2003, 2, 10, 23, 9, 27)]\n",
      "[datetime.datetime(2016, 12, 5, 0, 0)]\n",
      "[datetime.datetime(2010, 4, 22, 17, 12, 26)]\n",
      "[datetime.datetime(2009, 5, 4, 6, 36, 25)]\n",
      "[datetime.datetime(2011, 8, 8, 0, 22)]\n",
      "[datetime.datetime(2011, 8, 18, 18, 1, 27)]\n",
      "[datetime.datetime(2008, 1, 31, 18, 58, 55)]\n",
      "[datetime.datetime(2015, 11, 3, 0, 0)]\n",
      "[datetime.datetime(2011, 9, 18, 0, 0)]\n",
      "[datetime.datetime(2016, 7, 21, 0, 0)]\n",
      "[datetime.datetime(2002, 4, 5, 3, 55, 48)]\n",
      "no creation date for presstv.ir\n",
      "[datetime.datetime(2001, 6, 14, 6, 32, 34)]\n",
      "[datetime.datetime(2008, 11, 11, 15, 35, 34)]\n",
      "[datetime.datetime(2016, 2, 15, 15, 3)]\n",
      "[datetime.datetime(2003, 4, 15, 1, 57, 19)]\n",
      "[datetime.datetime(2009, 4, 15, 0, 0)]\n",
      "[datetime.datetime(2013, 4, 21, 20, 40)]\n",
      "[datetime.datetime(2012, 6, 17, 3, 30)]\n",
      "[datetime.datetime(2013, 1, 14, 0, 0)]\n",
      "[datetime.datetime(2016, 5, 14, 3, 40)]\n",
      "[datetime.datetime(1999, 3, 10, 5, 0)]\n",
      "[datetime.datetime(2012, 5, 5, 20, 52)]\n",
      "[datetime.datetime(2003, 2, 27, 0, 0)]\n",
      "[datetime.datetime(2012, 3, 12, 18, 46, 15)]\n",
      "[datetime.datetime(1991, 9, 23, 4, 0)]\n",
      "[datetime.datetime(2013, 5, 13, 22, 19, 43)]\n",
      "[datetime.datetime(2014, 8, 12, 0, 0)]\n",
      "[datetime.datetime(1999, 12, 2, 0, 0)]\n",
      "[datetime.datetime(2010, 12, 8, 0, 0)]\n",
      "[datetime.datetime(2015, 4, 22, 15, 54)]\n",
      "[datetime.datetime(2011, 8, 8, 0, 0)]\n",
      "[datetime.datetime(2009, 1, 3, 0, 0)]\n",
      "[datetime.datetime(2011, 4, 10, 0, 0)]\n",
      "[datetime.datetime(2007, 10, 24, 14, 35, 26)]\n",
      "[datetime.datetime(2015, 4, 30, 14, 38, 20)]\n",
      "[datetime.datetime(2016, 6, 18, 15, 50)]\n",
      "[datetime.datetime(2011, 10, 24, 0, 15, 14)]\n",
      "[datetime.datetime(2010, 6, 8, 15, 29, 2)]\n",
      "[datetime.datetime(2012, 10, 3, 15, 18)]\n",
      "[datetime.datetime(2016, 2, 25, 0, 0)]\n",
      "[datetime.datetime(2012, 5, 30, 23, 51, 15)]\n",
      "[datetime.datetime(2012, 8, 31, 21, 16, 27)]\n",
      "[datetime.datetime(2013, 2, 25, 0, 0)]\n",
      "[datetime.datetime(2008, 6, 19, 0, 0)]\n",
      "[datetime.datetime(2010, 2, 12, 0, 0)]\n",
      "[datetime.datetime(2004, 5, 21, 0, 0)]\n",
      "[datetime.datetime(2016, 4, 26, 9, 2)]\n",
      "no creation date for theearthchild.co.za\n",
      "[datetime.datetime(2009, 12, 24, 0, 0)]\n",
      "[datetime.datetime(2014, 4, 18, 0, 0)]\n",
      "[datetime.datetime(2011, 2, 26, 0, 35, 37)]\n",
      "[datetime.datetime(2013, 10, 8, 0, 0)]\n",
      "[datetime.datetime(2016, 1, 19, 1, 31, 59)]\n",
      "[datetime.datetime(2013, 1, 18, 0, 38)]\n",
      "[datetime.datetime(1999, 4, 15, 0, 0)]\n",
      "[datetime.datetime(1995, 3, 21, 5, 0)]\n",
      "[datetime.datetime(2005, 1, 11, 0, 0)]\n",
      "[datetime.datetime(2002, 3, 22, 0, 0), datetime.datetime(2002, 3, 22, 0, 0), datetime.datetime(2002, 3, 22, 0, 0)]\n",
      "[datetime.datetime(2013, 3, 27, 14, 4, 31)]\n",
      "no creation date for thesaker.is\n",
      "[datetime.datetime(2012, 10, 10, 1, 43, 36)]\n",
      "[datetime.datetime(2003, 3, 25, 0, 0)]\n",
      "[datetime.datetime(2002, 8, 30, 0, 0), datetime.datetime(2002, 8, 30, 0, 0), datetime.datetime(2002, 8, 30, 0, 0)]\n",
      "[datetime.datetime(2011, 5, 4, 0, 0)]\n",
      "[datetime.datetime(2013, 3, 29, 0, 0)]\n",
      "[datetime.datetime(2013, 8, 8, 0, 0)]\n",
      "[datetime.datetime(2011, 9, 7, 0, 0)]\n",
      "[datetime.datetime(2003, 8, 2, 0, 0)]\n",
      "[datetime.datetime(2010, 2, 17, 19, 53, 11)]\n",
      "[datetime.datetime(2004, 9, 8, 0, 12, 32)]\n",
      "[datetime.datetime(2015, 1, 1, 0, 0)]\n",
      "[datetime.datetime(2002, 11, 27, 7, 18, 29)]\n",
      "[datetime.datetime(2015, 8, 26, 0, 0)]\n",
      "[datetime.datetime(2008, 1, 8, 0, 0)]\n",
      "[datetime.datetime(1997, 11, 6, 0, 0)]\n",
      "[datetime.datetime(2016, 1, 1, 18, 20)]\n",
      "[datetime.datetime(2016, 5, 6, 17, 31, 50)]\n",
      "[datetime.datetime(2016, 3, 23, 14, 55, 36)]\n",
      "[datetime.datetime(2016, 5, 13, 0, 0)]\n",
      "[datetime.datetime(2015, 11, 30, 18, 37, 35)]\n",
      "[datetime.datetime(2006, 7, 10, 0, 0)]\n",
      "[datetime.datetime(1999, 10, 25, 4, 0)]\n",
      "[datetime.datetime(2011, 6, 21, 0, 0)]\n",
      "[datetime.datetime(2004, 7, 14, 0, 0)]\n",
      "[datetime.datetime(2008, 11, 20, 15, 23, 9)]\n",
      "[datetime.datetime(2015, 11, 3, 20, 3, 9)]\n",
      "[datetime.datetime(2005, 8, 24, 10, 1, 28)]\n",
      "[datetime.datetime(2011, 10, 28, 0, 0)]\n",
      "[datetime.datetime(2009, 3, 19, 6, 2, 58)]\n",
      "[datetime.datetime(2010, 2, 24, 11, 44, 2)]\n",
      "[datetime.datetime(2006, 11, 13, 16, 36, 12)]\n",
      "[datetime.datetime(2000, 2, 22, 21, 9)]\n",
      "[datetime.datetime(1999, 10, 11, 20, 43, 48)]\n",
      "[datetime.datetime(2013, 2, 8, 0, 0)]\n",
      "[datetime.datetime(2006, 10, 4, 5, 54, 19)]\n",
      "[datetime.datetime(2015, 9, 2, 0, 0)]\n",
      "[datetime.datetime(1998, 9, 23, 4, 0)]\n",
      "[datetime.datetime(2011, 12, 10, 18, 14, 21)]\n",
      "[datetime.datetime(2013, 6, 25, 20, 32, 50)]\n",
      "[datetime.datetime(2014, 8, 4, 0, 0)]\n",
      "[datetime.datetime(2009, 1, 11, 17, 14, 37)]\n"
     ]
    }
   ],
   "source": [
    "for xx in meta_fake.keys():\n",
    "    try:\n",
    "        print(meta_fake[xx]['creation_date'])\n",
    "    except (TypeError,KeyError):\n",
    "        print('no creation date for ' + xx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## query for the true set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_urls = ['nytimes.com', 'wsj.com', 'abcnews.go.com', 'cnn.com', 'cbsnews.com', 'foxnews.com', 'msnbc.com',\n",
    "                  'nbcnews.com','oann.com', 'latimes.com', 'usatoday.com', 'washingtonpost.com', 'newsweek.com',\n",
    "                  'time.com', 'usnews.com', 'theguardian.com', 'telegraph.co.uk', 'thetimes.co.uk', 'ft.com',\n",
    "                  'independent.co.uk', 'bbc.com', 'standard.co.uk', 'dailymail.co.uk', 'express.co.uk',\n",
    "                  'dailytelegraph.com.au', 'thestar.com','theglobeandmail.com', 'nationalpost.com',\n",
    "                   'calgaryherald.com', 'herald.ie', 'irishtimes.com', 'independent.ie', 'afr.com.au',\n",
    "                   'theaustralian.com.au', 'thesaturdaypaper.com.au', 'reddit.com', 'Cnn.com', 'Bbc.co.uk', 'Weather.com',\n",
    "                   'News.yahoo.com', 'Huffingtonpost.com','Forbes.com', 'Foxnews.com', 'news.google.com' ,\n",
    "                   'Shutterstock.com', 'Timesofindia.indiatimes.com', 'Bloomberg.com', 'Reuters.com', 'Wunderground.com',\n",
    "                   'Money.cnn.com', 'Indianexpress.com', 'Nbcnews.com', 'Latimes.com', 'cnbc.com', 'cbsnews.com',\n",
    "                   'vox.com', 'Abcnews.go.com', 'Nypost.com', 'Theatlantic.com', 'Chicagotribune.com', 'Chinadaily.com.cn'\n",
    "                   ,'Hollywoodreporter.com', 'Sfgate.com', 'Usnews.com', 'Economist.com', 'Aljazeera.com', 'Fortune.com',\n",
    "                   'Newsnow.co.uk', 'Variety.com', 'Euronews.com', 'Washingtontimes.com', 'Bostonglobe.com', 'Newsweek.com'\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meta_true = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nytimes.com\n",
      "wsj.com\n",
      "abcnews.go.com\n",
      "cnn.com\n",
      "cbsnews.com\n",
      "foxnews.com\n",
      "msnbc.com\n",
      "nbcnews.com\n",
      "oann.com\n",
      "latimes.com\n",
      "usatoday.com\n",
      "washingtonpost.com\n",
      "newsweek.com\n",
      "time.com\n",
      "usnews.com\n",
      "theguardian.com\n",
      "telegraph.co.uk\n",
      "thetimes.co.uk\n",
      "ft.com\n",
      "independent.co.uk\n",
      "bbc.com\n",
      "standard.co.uk\n",
      "dailymail.co.uk\n",
      "express.co.uk\n",
      "dailytelegraph.com.au\n",
      "thestar.com\n",
      "theglobeandmail.com\n",
      "nationalpost.com\n",
      "calgaryherald.com\n",
      "herald.ie\n",
      "irishtimes.com\n",
      "independent.ie\n",
      "afr.com.au\n",
      "theaustralian.com.au\n",
      "thesaturdaypaper.com.au\n",
      "reddit.com\n",
      "Cnn.com\n",
      "Bbc.co.uk\n",
      "Weather.com\n",
      "News.yahoo.com\n",
      "Huffingtonpost.com\n",
      "Forbes.com\n",
      "Foxnews.com\n",
      "news.google.com\n",
      "Shutterstock.com\n",
      "Timesofindia.indiatimes.com\n",
      "Bloomberg.com\n",
      "Reuters.com\n",
      "Wunderground.com\n",
      "Money.cnn.com\n",
      "Indianexpress.com\n",
      "Nbcnews.com\n",
      "Latimes.com\n",
      "cnbc.com\n",
      "cbsnews.com\n",
      "vox.com\n",
      "Abcnews.go.com\n",
      "Nypost.com\n",
      "Theatlantic.com\n",
      "Chicagotribune.com\n",
      "Chinadaily.com.cn\n",
      "Hollywoodreporter.com\n",
      "Sfgate.com\n",
      "Usnews.com\n",
      "Economist.com\n",
      "Aljazeera.com\n",
      "Fortune.com\n",
      "Newsnow.co.uk\n",
      "Variety.com\n",
      "Euronews.com\n",
      "Washingtontimes.com\n",
      "Bostonglobe.com\n",
      "Newsweek.com\n"
     ]
    }
   ],
   "source": [
    "find_url_meta(good_urls, meta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nytimes.com\n",
      "1994\n",
      "wsj.com\n",
      "1994\n",
      "abcnews.go.com\n",
      "no creation date for abcnews.go.com\n",
      "cnn.com\n",
      "1993\n",
      "cbsnews.com\n",
      "1994\n",
      "foxnews.com\n",
      "1995\n",
      "msnbc.com\n",
      "1995\n",
      "nbcnews.com\n",
      "1997\n",
      "oann.com\n",
      "2004\n",
      "latimes.com\n",
      "1990\n",
      "usatoday.com\n",
      "1994\n",
      "washingtonpost.com\n",
      "1995\n",
      "newsweek.com\n",
      "1994\n",
      "time.com\n",
      "1993\n",
      "usnews.com\n",
      "1995\n",
      "theguardian.com\n",
      "1994\n",
      "telegraph.co.uk\n",
      "no creation date for telegraph.co.uk\n",
      "thetimes.co.uk\n",
      "1996\n",
      "ft.com\n",
      "1994\n",
      "independent.co.uk\n",
      "no creation date for independent.co.uk\n",
      "bbc.com\n",
      "1989\n",
      "standard.co.uk\n",
      "no creation date for standard.co.uk\n",
      "dailymail.co.uk\n",
      "no creation date for dailymail.co.uk\n",
      "express.co.uk\n",
      "no creation date for express.co.uk\n",
      "dailytelegraph.com.au\n",
      "no creation date for dailytelegraph.com.au\n",
      "thestar.com\n",
      "1995\n",
      "theglobeandmail.com\n",
      "1995\n",
      "nationalpost.com\n",
      "1998\n",
      "calgaryherald.com\n",
      "1995\n",
      "herald.ie\n",
      "2006\n",
      "irishtimes.com\n",
      "1997\n",
      "independent.ie\n",
      "2001\n",
      "afr.com.au\n",
      "no creation date for afr.com.au\n",
      "theaustralian.com.au\n",
      "no creation date for theaustralian.com.au\n",
      "thesaturdaypaper.com.au\n",
      "no creation date for thesaturdaypaper.com.au\n",
      "reddit.com\n",
      "2005\n",
      "Cnn.com\n",
      "1993\n",
      "Bbc.co.uk\n",
      "no creation date for Bbc.co.uk\n",
      "Weather.com\n",
      "1994\n",
      "News.yahoo.com\n",
      "no creation date for News.yahoo.com\n",
      "Huffingtonpost.com\n",
      "2005\n",
      "Forbes.com\n",
      "1993\n",
      "news.google.com\n",
      "no creation date for news.google.com\n",
      "Shutterstock.com\n",
      "2003\n",
      "Timesofindia.indiatimes.com\n",
      "no creation date for Timesofindia.indiatimes.com\n",
      "Bloomberg.com\n",
      "1993\n",
      "Reuters.com\n",
      "1993\n",
      "Wunderground.com\n",
      "1995\n",
      "Money.cnn.com\n",
      "no creation date for Money.cnn.com\n",
      "Nbcnews.com\n",
      "1997\n",
      "cnbc.com\n",
      "1997\n",
      "vox.com\n",
      "1994\n",
      "Abcnews.go.com\n",
      "no creation date for Abcnews.go.com\n",
      "Nypost.com\n",
      "1996\n",
      "Theatlantic.com\n",
      "1995\n",
      "Chicagotribune.com\n",
      "1998\n",
      "Chinadaily.com.cn\n",
      "no creation date for Chinadaily.com.cn\n",
      "Hollywoodreporter.com\n",
      "1995\n",
      "Sfgate.com\n",
      "1994\n",
      "Usnews.com\n",
      "1995\n",
      "Economist.com\n",
      "1994\n",
      "Aljazeera.com\n",
      "1996\n",
      "Newsnow.co.uk\n",
      "1997\n",
      "Variety.com\n",
      "1996\n",
      "Euronews.com\n",
      "1997\n",
      "Washingtontimes.com\n",
      "1998\n",
      "Bostonglobe.com\n",
      "1998\n",
      "Newsweek.com\n",
      "1994\n"
     ]
    }
   ],
   "source": [
    "for xx in meta_true.keys():\n",
    "    try:\n",
    "        print(xx)\n",
    "        print(int(meta_true[xx]['creation_date'][0].year))\n",
    "    except (TypeError,KeyError):\n",
    "        print('no creation date for ' + xx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ok lets create outside nlp feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def year_bias(year):\n",
    "    if year<2000:\n",
    "        return 1\n",
    "    elif year>2000:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_to_file(object_to_save, name_on_disc, pick):\n",
    "    if pick:\n",
    "        with open(name_on_disc + '.pickle', 'wb') as handle:\n",
    "            pickle.dump(object_to_save, handle)\n",
    "    else:\n",
    "        with open(name_on_disc, 'wb') as handle:\n",
    "            pickle.dump(object_to_save, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_to_file(meta_fake, 'fake_urls_metadata', pick=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_to_file(meta_true, 'true_urls_metadata', pick=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
