{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## lets build up that profanity checker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# profanity filter\n",
    "# The list of profane words is in profane_words.txt. Each word has a\n",
    "# \"score\" associated with it between 1-10 to indicate the severity of the\n",
    "# profanity\n",
    "#\n",
    "# Following steps are followed:\n",
    "# 1. Check for individual words: eg - fuck\n",
    "# 2. Check for transposed words: eg - fcuk, f**k, sh!t\n",
    "# 3. Check for compound/broken words: eg - ass hole, ass-hole.\n",
    "# 4. Check for adjectivish words: eg - assholish behavior\n",
    "\n",
    "import string\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "import utilities\n",
    "\n",
    "GROUP_SIZE = 2\n",
    "CHAR_MATCH_HEURISTIC = 0.8\n",
    "\n",
    "SPECIAL_CHAR_ALIASES = {\n",
    "    's': '$',\n",
    "    'i': '!',\n",
    "    'l': '1',\n",
    "    'a': '@',\n",
    "    'e': '3',\n",
    "    'g': '8',\n",
    "    'o': '0',\n",
    "    'u': '4'\n",
    "}\n",
    "\n",
    "\n",
    "def profanityScore(text):\n",
    "    \"\"\"\n",
    "    Returns a number between 1 and 10 that represents the profanity score\n",
    "    for the text of string\n",
    "    \"\"\"\n",
    "\n",
    "    profane_word_weights = utilities.readPropertiesFile('profane_words.txt', 'int')\n",
    "    profane_words = profane_word_weights.keys()\n",
    "\n",
    "    words_dict = utilities.readPropertiesFile('dict_words.txt', 'list')\n",
    "\n",
    "    profane_words_transpose = {}\n",
    "    for w in profane_words:\n",
    "        profane_words_transpose[w] = getTransposedWords(w)\n",
    "\n",
    "    # utilities.prettyPrintDict(profane_words_transpose)\n",
    "\n",
    "    words = [w.rstrip('.') for w in text.lower().split()]\n",
    "\n",
    "    score = 0.0\n",
    "    words_count = defaultdict(int)\n",
    "\n",
    "    for w in words:\n",
    "        inDict = w in words_dict[w[0]]\n",
    "\n",
    "        w = utilities.rot13(w)\n",
    "\n",
    "        # If the exact word appears in the list of profane words\n",
    "        if w in profane_words:\n",
    "            words_count[w] += 1\n",
    "\n",
    "        # Check if the word is a transpose of the profane words\n",
    "        for pw in profane_words_transpose.keys():\n",
    "            if w in profane_words_transpose[pw]:\n",
    "                words_count[pw] += 1\n",
    "\n",
    "        # Check if profane words is a substring of the word\n",
    "        for pw in profane_words:\n",
    "            if w.find(pw) != -1 and not inDict:\n",
    "                words_count[pw] += 1\n",
    "\n",
    "    # Take words GROUP_SIZE at a time and see if they either form a\n",
    "    # profane word, or the beginning of one.\n",
    "    # If they form a profane word, update the count. If they form the\n",
    "    # beginning of a profane word, then see if it actually matches one\n",
    "    # and then count as one\n",
    "\n",
    "    for i in range(len(words) - GROUP_SIZE):\n",
    "        concat_word = words[i] + words[i + 1] + words[i + 2]\n",
    "        concat_word = utilities.rot13(concat_word)\n",
    "\n",
    "        for pw in profane_words:\n",
    "\n",
    "            if pw.find(concat_word) != -1:\n",
    "                if checkMatchPercent(len(concat_word), len(pw)):\n",
    "                    words_count[pw] += 1\n",
    "                    break\n",
    "\n",
    "                # check further...\n",
    "                j = 2\n",
    "                while True:\n",
    "                    j += 1\n",
    "                    if i + j > len(words) - 1:\n",
    "                        break\n",
    "\n",
    "                    concat_word += utilities.rot13(words[i + j])\n",
    "\n",
    "                    # continue while we keep on concatenating the\n",
    "                    # letters and find that it is a substring of an\n",
    "                    # actual profane word\n",
    "                    if pw.find(concat_word) != -1:\n",
    "                        continue\n",
    "                    # once the concatenated word is not a substring of\n",
    "                    # an actual profane word, see how far we have\n",
    "                    # reached i.e. does the word match a significant\n",
    "                    # number of characters of a profane word to be\n",
    "                    # counted as an actual profanity or not.\n",
    "                    # If that is the case, and the word is not a\n",
    "                    # dictionary word, then count it as an actual\n",
    "                    # profanity that was disguised\n",
    "                    elif checkMatchPercent(len(concat_word) - 1, len(pw)):\n",
    "                        words_count[pw] += 1\n",
    "                        break\n",
    "\n",
    "    # utilities.prettyPrintDict(words_count)\n",
    "\n",
    "    # compute the score\n",
    "    running_sum = 0\n",
    "    count = 0\n",
    "    for w in words_count.keys():\n",
    "        running_sum += words_count[w] * profane_word_weights[w]\n",
    "        count += words_count[w]\n",
    "\n",
    "    if count == 0:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = running_sum / count\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def getTransposedWords(word):\n",
    "    \"\"\"\n",
    "    Get a list of possible transpositions of the current profane word.\n",
    "    Transpositions include:\n",
    "        - Transposing two adjacent characters: eg - siht (for shit)\n",
    "        - Replacing two letters with **: eg - f**k\n",
    "        - Replacing letters with special characters: eg - $hit\n",
    "    eg - For the word \"shit\", we will return the following:\n",
    "        ['siht', 'shti', 's**it', 'sh**t', '$hit', 'sh!t']\n",
    "    \"\"\"\n",
    "    ret = []\n",
    "\n",
    "    # First iterate through the word and transpose 2 adjacent characters\n",
    "    # (leaving out the first and the last)\n",
    "    for i in range(1, len(word) - 1):\n",
    "        ret.append(word[:i] + word[i + 1] + word[i] + word[i + 2:])\n",
    "\n",
    "    # Now replace letter pairs with *. Once again, skip the first and last\n",
    "    # characters\n",
    "    for i in range(1, len(word) - 1):\n",
    "        ret.append(word[:i] + '**' + word[i + 2:])\n",
    "\n",
    "    # Now repalce words with special characters\n",
    "    for ch in SPECIAL_CHAR_ALIASES.keys():\n",
    "        if word.find(ch) != -1:\n",
    "            ret.append(word.replace(ch, SPECIAL_CHAR_ALIASES[ch]))\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def checkMatchPercent(partialWordLen, wordLen):\n",
    "    if wordLen <= 4 and partialWordLen >= 3:\n",
    "        return True\n",
    "    elif partialWordLen / wordLen > CHAR_MATCH_HEURISTIC:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = 'assholežgs§aał’ß§'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assholegsaa\n"
     ]
    }
   ],
   "source": [
    "print(''.join(x for x in s if x in string.printable)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
